{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FCC-GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSBp94YLLz5zTJp3gSlvg6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmadArrabi/Cat-Generation-using-GANs/blob/main/FCC_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dZnNyGFZpFo"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dC9SwHNSojo"
      },
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq0C5o81Utp4",
        "outputId": "c9236da4-b996-4e9b-9e85-79adcb7b5bc5"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgqC62GzIte4"
      },
      "source": [
        "dataset = keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/data/dataset/dataset3/cats2\",\n",
        "    label_mode=None,\n",
        "    image_size=(64, 64),\n",
        "    batch_size=128,\n",
        "    color_mode = 'rgb'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCfPv-CwJm3J"
      },
      "source": [
        "dataset = dataset.map(lambda x: x / 255.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px9dR7x1J_dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b708ef2-d40f-4822-b1a5-7a95026ccabb"
      },
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "     keras.Input(shape = (64,64,3)),\n",
        "     keras.layers.Conv2D(filters=128, kernel_size=5, strides=2, padding='same'),\n",
        "     #keras.layers.AveragePooling2D(pool_size=(2,2)),\n",
        "     keras.layers.BatchNormalization(),\n",
        "     keras.layers.LeakyReLU(0.2),\n",
        "     keras.layers.Conv2D(filters=256, kernel_size=5, strides=2, padding='same'),\n",
        "     #keras.layers.AveragePooling2D(pool_size=(2,2)),\n",
        "     keras.layers.BatchNormalization(),\n",
        "     keras.layers.LeakyReLU(0.2),\n",
        "     keras.layers.Conv2D(filters=512, kernel_size=5, strides=2, padding='same'),\n",
        "     #keras.layers.AveragePooling2D(pool_size=(2,2)),\n",
        "     keras.layers.BatchNormalization(),\n",
        "     keras.layers.LeakyReLU(0.2),\n",
        "     keras.layers.Conv2D(filters=1024, kernel_size=5, strides=2, padding='same'),\n",
        "     #keras.layers.AveragePooling2D(pool_size=(2,2)),\n",
        "     keras.layers.BatchNormalization(),\n",
        "     keras.layers.LeakyReLU(0.2),\n",
        "     keras.layers.Flatten(),\n",
        "     #keras.layers.Dense(1024),\n",
        "     #keras.layers.LeakyReLU(0.2),\n",
        "     keras.layers.Dense(512),\n",
        "     keras.layers.LeakyReLU(0.2),\n",
        "     keras.layers.BatchNormalization(),\n",
        "     keras.layers.Dense(128),\n",
        "     keras.layers.LeakyReLU(0.2),\n",
        "     keras.layers.BatchNormalization(),\n",
        "     keras.layers.Dense(16),\n",
        "     keras.layers.LeakyReLU(0.2),\n",
        "     keras.layers.BatchNormalization(),\n",
        "     keras.layers.Dense(1, activation = 'sigmoid')\n",
        "    ]\n",
        ")\n",
        "discriminator.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 128)       9728      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 256)       819456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 512)         3277312   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 1024)        13108224  \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 4, 4, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 1024)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               8389120   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                2064      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 25,681,889\n",
            "Trainable params: 25,676,737\n",
            "Non-trainable params: 5,152\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vtKEHsmMQQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9028986-ad97-4b47-de42-0f3eb7e188d7"
      },
      "source": [
        "latent_dim = 128\n",
        "\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "     keras.Input(shape = (latent_dim,)),\n",
        "     keras.layers.Dense(64, activation='relu'),\n",
        "     keras.layers.BatchNormalization(),\n",
        "     keras.layers.Dense(512, activation='relu'),\n",
        "     keras.layers.BatchNormalization(),\n",
        "     #keras.layers.Dense(1024, activation='relu'),\n",
        "     keras.layers.Dense(16384, activation='relu'),\n",
        "     keras.layers.BatchNormalization(),\n",
        "     keras.layers.Reshape((4,4,1024)),\n",
        "     keras.layers.Conv2DTranspose(filters=512, kernel_size=4, strides=2, padding='same', activation='relu'),\n",
        "     keras.layers.BatchNormalization(),\n",
        "     keras.layers.Conv2DTranspose(filters=256, kernel_size=4, strides=2, padding='same', activation='relu'),\n",
        "     keras.layers.BatchNormalization(),\n",
        "     keras.layers.Conv2DTranspose(filters=128, kernel_size=4, strides=2, padding='same', activation='relu'),\n",
        "     keras.layers.BatchNormalization(),\n",
        "     keras.layers.Conv2DTranspose(filters=3, kernel_size=4, strides=2, padding='same', activation='tanh'),\n",
        "     #keras.layers.BatchNormalization(),\n",
        "    ]\n",
        ")\n",
        "generator.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               33280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 16384)             8404992   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 16384)             65536     \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 4, 4, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 8, 8, 512)         8389120   \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 16, 16, 256)       2097408   \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 128)       524416    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 64, 64, 3)         6147      \n",
            "=================================================================\n",
            "Total params: 19,535,043\n",
            "Trainable params: 19,499,331\n",
            "Non-trainable params: 35,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIiO_ViORCTD"
      },
      "source": [
        "gen_opt = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.00001)\n",
        "disc_opt = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.00001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0NVw1WzdFyH"
      },
      "source": [
        "loss = keras.losses.BinaryCrossentropy()\n",
        "latent_dim = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOyS3vM3dRvR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "outputId": "4507356f-54e2-4fa5-8491-3afce8f47c88"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from tensorflow import keras\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  for epoch in range(100):\n",
        "    for idx, real in enumerate(tqdm(dataset)):\n",
        "      batch_size = real.shape[0]\n",
        "      random_latent_vector = tf.random.normal(shape=(batch_size, latent_dim))\n",
        "      fake = generator(random_latent_vector)\n",
        "\n",
        "      if idx % 100 == 0:\n",
        "        img = keras.preprocessing.image.array_to_img(fake[0])\n",
        "        img.save(\"/content/drive/MyDrive/data/dataset/generated4/take6/generated_img_%03d_%d.jpg\" % (epoch, idx))\n",
        "      \n",
        "      #Train Discriminator ylog(y') + (1-y)log(1-y') => ylog(D(x)) + (1-y)log(1-D(G(z)))\n",
        "      with tf.GradientTape() as disc_tape:\n",
        "        loss_disc_real = loss(tf.ones((batch_size,1)), discriminator(real))\n",
        "        loss_disc_fake = loss(tf.zeros((batch_size,1)), discriminator(fake))\n",
        "        loss_disc = (loss_disc_fake + loss_disc_real)\n",
        "      \n",
        "      grads = disc_tape.gradient(loss_disc, discriminator.trainable_weights)\n",
        "      disc_opt.apply_gradients(\n",
        "          zip(grads, discriminator.trainable_weights)\n",
        "      )\n",
        "      \n",
        "      #Train generator: log(D(G(z)))\n",
        "      with tf.GradientTape() as gen_tape:\n",
        "        fake = generator(random_latent_vector)\n",
        "        output = discriminator(fake)\n",
        "        loss_gen = loss(tf.ones(batch_size,1), output)\n",
        "      \n",
        "      grads = gen_tape.gradient(loss_gen, generator.trainable_weights)\n",
        "      gen_opt.apply_gradients(\n",
        "          zip(grads, generator.trainable_weights)\n",
        "      )\n",
        "      #2h+ without pooling layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 36/36 [25:22<00:00, 42.28s/it]\n",
            "100%|██████████| 36/36 [01:00<00:00,  1.68s/it]\n",
            "100%|██████████| 36/36 [01:21<00:00,  2.28s/it]\n",
            "100%|██████████| 36/36 [01:01<00:00,  1.71s/it]\n",
            "100%|██████████| 36/36 [01:21<00:00,  2.28s/it]\n",
            "100%|██████████| 36/36 [01:01<00:00,  1.70s/it]\n",
            "100%|██████████| 36/36 [01:01<00:00,  1.71s/it]\n",
            "100%|██████████| 36/36 [01:21<00:00,  2.28s/it]\n",
            "100%|██████████| 36/36 [01:01<00:00,  1.71s/it]\n",
            "100%|██████████| 36/36 [01:21<00:00,  2.28s/it]\n",
            "100%|██████████| 36/36 [01:21<00:00,  2.28s/it]\n",
            "100%|██████████| 36/36 [01:01<00:00,  1.70s/it]\n",
            "100%|██████████| 36/36 [01:21<00:00,  2.28s/it]\n",
            "100%|██████████| 36/36 [01:21<00:00,  2.28s/it]\n",
            "100%|██████████| 36/36 [01:01<00:00,  1.70s/it]\n",
            "100%|██████████| 36/36 [01:21<00:00,  2.28s/it]\n",
            "100%|██████████| 36/36 [01:01<00:00,  1.70s/it]\n",
            "100%|██████████| 36/36 [01:01<00:00,  1.71s/it]\n",
            "100%|██████████| 36/36 [01:21<00:00,  2.28s/it]\n",
            "100%|██████████| 36/36 [01:01<00:00,  1.70s/it]\n",
            "100%|██████████| 36/36 [01:21<00:00,  2.28s/it]\n",
            "100%|██████████| 36/36 [01:01<00:00,  1.71s/it]\n",
            "100%|██████████| 36/36 [01:01<00:00,  1.71s/it]\n",
            "100%|██████████| 36/36 [01:21<00:00,  2.28s/it]\n",
            "100%|██████████| 36/36 [01:01<00:00,  1.71s/it]\n",
            " 33%|███▎      | 12/36 [00:22<00:44,  1.83s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-520b6b8e0c5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;31m#Train Discriminator ylog(y') + (1-y)log(1-y') => ylog(D(x)) + (1-y)log(1-D(G(z)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss_disc_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss_disc_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss_disc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_disc_fake\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_disc_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    367\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 415\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1136\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1269\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2720\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2721\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2722\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2723\u001b[0m   return squeeze_batch_dims(\n\u001b[1;32m   2724\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNTZeArG7l48"
      },
      "source": [
        "## Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8Q9qsRJHZOq"
      },
      "source": [
        "import os.path\n",
        "if os.path.isfile('/content/drive/MyDrive/data/models/FCC-GAN/generator.h5') is False:\n",
        "  generator.save('/content/drive/MyDrive/data/models/FCC-GAN/generator.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjS0AHyVH3XC"
      },
      "source": [
        "if os.path.isfile('/content/drive/MyDrive/data/models/FCC-GAN/dicriminator.h5') is False:\n",
        "  discriminator.save('/content/drive/MyDrive/data/models/FCC-GAN/dicriminator.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfUjPyyxeHo2"
      },
      "source": [
        "#for epoch in range(100):\n",
        "#  for idx, real in enumerate(tqdm(dataset)):\n",
        "#    batch_size = real.shape[0]\n",
        "#\n",
        "#    #generate random images\n",
        "#    random_latent_vector = tf.random.normal(shape=(batch_size, latent_dim))\n",
        "#    fake = generator(random_latent_vector)\n",
        "#    \n",
        "#    #save image in each epoch\n",
        "#    if idx % 100 == 0:\n",
        "#        img = keras.preprocessing.image.array_to_img(fake[0])\n",
        "#        img.save(\"/content/drive/MyDrive/data/dataset/generated4/generated_img_%03d_%d.jpg\" % (epoch, idx))\n",
        "#    \n",
        "#    #train discriminator\n",
        "#    with tf.GradientTape() as disc_tape:\n",
        "#      "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}